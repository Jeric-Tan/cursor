<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion Recognition Test</title>
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <div id="app">
        <!-- Emotion Recognition Test Stage -->
        <div id="emotion-recognition-stage" class="stage active">
            <h2>üé≠ Emotion Recognition Test</h2>
            <p>Test the real-time emotion detection system</p>
            
            <div id="camera-container">
                <video id="camera-feed" autoplay muted style="display: none;"></video>
                <canvas id="emotion-canvas" style="display: block;"></canvas>
            </div>
            
            <div id="emotion-display">
                <div id="current-emotion">No emotion detected</div>
                <div id="emotion-confidence">Confidence: 0%</div>
            </div>
            
            <div id="emotion-controls">
                <button id="start-camera-btn">Start Camera</button>
                <button id="stop-camera-btn" disabled>Stop Camera</button>
                <button id="test-websocket-btn">Test WebSocket</button>
            </div>
            
            <div id="status-display">
                <div id="connection-status">WebSocket: Disconnected</div>
                <div id="camera-status">Camera: Not Started</div>
            </div>
        </div>
    </div>

    <script type="module">
        // Test state
        const state = {
            cameraStream: null,
            websocket: null,
            isEmotionDetectionActive: false,
            currentEmotion: null,
            emotionConfidence: 0
        };

        // Initialize test
        document.addEventListener('DOMContentLoaded', () => {
            setupEventListeners();
        });

        function setupEventListeners() {
            document.getElementById('start-camera-btn').addEventListener('click', startEmotionDetection);
            document.getElementById('stop-camera-btn').addEventListener('click', stopEmotionDetection);
            document.getElementById('test-websocket-btn').addEventListener('click', testWebSocket);
        }

        // Emotion Recognition Functions
        async function startEmotionDetection() {
            try {
                console.log('üîó Connecting to emotion recognition service...');
                updateStatus('camera-status', 'Connecting...');
                
                // Connect to WebSocket - backend handles camera and sends annotated frames
                await connectToEmotionWebSocket();
                
                // Update UI
                document.getElementById('start-camera-btn').disabled = true;
                document.getElementById('stop-camera-btn').disabled = false;
                
                state.isEmotionDetectionActive = true;
                updateStatus('camera-status', 'Camera: Active (with green boxes!)');
                
                console.log('‚úÖ Emotion detection active with face tracking!');
                
            } catch (error) {
                console.error('‚ùå Error:', error);
                alert('Error connecting to emotion service: ' + error.message);
                updateStatus('camera-status', 'Error');
            }
        }

        async function connectToEmotionWebSocket() {
            try {
                console.log('üîó Connecting to WebSocket...');
                updateStatus('connection-status', 'WebSocket: Connecting...');
                
                // Connect to Python backend WebSocket
                state.websocket = new WebSocket('ws://localhost:8765');
                
                state.websocket.onopen = () => {
                    console.log('‚úÖ Connected to emotion recognition service');
                    updateStatus('connection-status', 'WebSocket: Connected');
                };
                
                state.websocket.onmessage = (event) => {
                    try {
                        const data = JSON.parse(event.data);
                        console.log('üì® Received emotion data:', data);
                        
                        if (data.type === 'emotion_frame') {
                            updateEmotionDisplay(data);
                        }
                    } catch (error) {
                        console.error('‚ùå Error parsing emotion data:', error);
                    }
                };
                
                state.websocket.onclose = () => {
                    console.log('üîå Disconnected from emotion recognition service');
                    updateStatus('connection-status', 'WebSocket: Disconnected');
                };
                
                state.websocket.onerror = (error) => {
                    console.error('‚ùå WebSocket error:', error);
                    updateStatus('connection-status', 'WebSocket: Error');
                };
                
            } catch (error) {
                console.error('‚ùå WebSocket connection error:', error);
                updateStatus('connection-status', 'WebSocket: Connection Failed');
            }
        }

        function updateEmotionDisplay(data) {
            // Always try to display the frame if available
            if (data.frame && data.frame.length > 0) {
                displayAnnotatedFrame(data.frame);
            }
            
            if (data.emotions && data.emotions.length > 0) {
                const emotion = data.emotions[0];
                const dominantEmotion = emotion.dominant_emotion;
                const confidence = Math.round(emotion.emotion[dominantEmotion] * 100);
                
                // Update emotion display
                document.getElementById('current-emotion').textContent = dominantEmotion;
                document.getElementById('emotion-confidence').textContent = `Confidence: ${confidence}%`;
                
                // Update state
                state.currentEmotion = dominantEmotion;
                state.emotionConfidence = confidence;
                
                console.log(`üòä Detected emotion: ${dominantEmotion} (${confidence}%)`);
            } else {
                document.getElementById('current-emotion').textContent = 'No emotion detected';
                document.getElementById('emotion-confidence').textContent = 'Confidence: 0%';
            }
        }

        function displayAnnotatedFrame(frameData) {
            const canvas = document.getElementById('emotion-canvas');
            if (!canvas) {
                console.error('Canvas element not found!');
                return;
            }
            
            const ctx = canvas.getContext('2d');
            
            // Create image from base64 data
            const img = new Image();
            img.onload = () => {
                try {
                    // Set canvas size to match the image (only if different)
                    if (canvas.width !== img.width || canvas.height !== img.height) {
                        canvas.width = img.width;
                        canvas.height = img.height;
                        console.log(`Canvas resized to ${img.width}x${img.height}`);
                    }
                    
                    // Clear canvas and draw the annotated frame
                    ctx.clearRect(0, 0, canvas.width, canvas.height);
                    ctx.drawImage(img, 0, 0);
                } catch (error) {
                    console.error('Error drawing image:', error);
                }
            };
            
            img.onerror = () => {
                console.error('Failed to load image from base64 data');
            };
            
            img.src = `data:image/jpeg;base64,${frameData}`;
        }

        function stopEmotionDetection() {
            console.log('üõë Stopping emotion detection...');
            
            // Close WebSocket connection (backend will release camera)
            if (state.websocket) {
                state.websocket.close();
                state.websocket = null;
            }
            
            // Update UI
            document.getElementById('start-camera-btn').disabled = false;
            document.getElementById('stop-camera-btn').disabled = true;
            
            state.isEmotionDetectionActive = false;
            updateStatus('camera-status', 'Stopped');
            updateStatus('connection-status', 'WebSocket: Disconnected');
            
            // Clear canvas
            const canvas = document.getElementById('emotion-canvas');
            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            console.log('‚úÖ Emotion detection stopped');
        }

        function testWebSocket() {
            console.log('üß™ Testing WebSocket connection...');
            if (state.websocket && state.websocket.readyState === WebSocket.OPEN) {
                console.log('‚úÖ WebSocket is connected');
                updateStatus('connection-status', 'WebSocket: Connected & Working');
            } else {
                console.log('‚ùå WebSocket is not connected');
                updateStatus('connection-status', 'WebSocket: Not Connected');
            }
        }

        function updateStatus(elementId, message) {
            const element = document.getElementById(elementId);
            if (element) {
                element.textContent = message;
            }
        }

        // Log startup
        console.log('üé≠ Emotion Recognition Test Page Loaded');
        console.log('üìã Instructions:');
        console.log('1. Make sure Python backend is running: python start_emotion_recognition.py');
        console.log('2. Click "Start Camera" to begin emotion detection');
        console.log('3. Check browser console for detailed logs');
    </script>
</body>
</html>
